{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change dir to root\n",
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import emrecdem as erd\n",
    "import textgrid\n",
    "import magic\n",
    "\n",
    "import importlib\n",
    "importlib.reload(erd)\n",
    "\n",
    "TOPICS_DIR = \"/Users/peter/repos/esc/data/Deniece/Textgrids_Timestamps_Participants_Face\"\n",
    "FEATURES_DIR = \"/Users/peter/repos/esc/data/Deniece/openface-features\"\n",
    "AGG_FEATURES_DIR = \"/Users/peter/repos/esc/data/Deniece/aggregated-features\"\n",
    "VIDEO_DIR = '/Volumes/vera_emrec/MEMOA_database'\n",
    "#VIDEO_DIR = '/media/peter/Data/esc/emrecdem/MEMOA_database'\n",
    "SILENCES_DIR = '/Users/peter/repos/esc/data/Deniece/Silence_textgrids_N17'\n",
    "\n",
    "def process_video(video_dir, video_title):\n",
    "    #cmd = f\"/Users/peter/repos/esc/emrecdem/emrecdem-framework/notebooks/process_video.sh {video_dir} {video_title}\"\n",
    "    cmd = f\"./process_video.sh {video_dir} {video_title}\"\n",
    "    print(cmd)\n",
    "    #!{cmd}\n",
    "    \n",
    "def parseTime(s):\n",
    "    split = s.split(':')\n",
    "    minutes = int(split[0])\n",
    "    seconds = float(split[1])\n",
    "    total_seconds = 60 * minutes + seconds\n",
    "    return total_seconds\n",
    "    \n",
    "def process_file(topics_file):\n",
    "    (participant, session, experiment, memory, _) = topics_file.split(\"_\")\n",
    "    \n",
    "    # Construct video path\n",
    "    video_title = f'{participant}_{session}_{experiment}_{memory}_Cfront'\n",
    "    video_dir = os.path.join(VIDEO_DIR, participant, session, 'Video', 'Single-angle')\n",
    "    \n",
    "    # Process video with openface\n",
    "    process_video(video_dir, video_title)\n",
    "    \n",
    "    # Load openface features\n",
    "    openface_file = os.path.join(FEATURES_DIR, video_title + '_features.csv')\n",
    "    openface_features = pd.read_csv(openface_file, skipinitialspace=True)\n",
    "    \n",
    "    # Load silences\n",
    "    silences_file = os.path.join(SILENCES_DIR, f'{participant}_{session}_{experiment}_{memory}_Mparticipant_SIL.TextGrid')\n",
    "    blob = open(silences_file, 'rb').read()\n",
    "    m = magic.Magic(mime_encoding=True)\n",
    "    encoding = m.from_buffer(blob)\n",
    "    silences_tgrid = textgrid.read_textgrid(silences_file, encoding)\n",
    "    silences = pd.DataFrame(silences_tgrid)\n",
    "    \n",
    "    # Add silences in column\n",
    "    def isSilent(timestamp):\n",
    "        filt = (silences['start'] <= timestamp) & (timestamp < silences['stop'])\n",
    "        return silences.loc[filt, 'name'].iat[0] == 'silent'\n",
    "    openface_features['silence'] = openface_features.apply(lambda row: isSilent(row.timestamp), axis=1)\n",
    "    \n",
    "    # Aggregate values (used for z-score calculation)\n",
    "    silent_features = openface_features[openface_features['silence'] == True]\n",
    "    video_aggregates = silent_features.aggregate(['mean', 'std'])\n",
    "    \n",
    "    # Write raw (debug)\n",
    "    output_file = \"_\".join([participant, session, experiment, memory]) + \"_raw.csv\"\n",
    "    output_path = os.path.join(AGG_FEATURES_DIR, output_file)\n",
    "    #openface_features.to_csv(output_path, float_format='%g', index=False)\n",
    "\n",
    "    # Process topics from file\n",
    "    aggregated_features = pd.DataFrame()\n",
    "    topics_path = os.path.join(TOPICS_DIR, topics_file)\n",
    "    with codecs.open(topics_path, 'r', encoding='cp1252') as file:\n",
    "        for line in file:\n",
    "            if not line.lower().startswith('timestamp'):\n",
    "                continue\n",
    "            \n",
    "            # Extract start and end time, topic index and text\n",
    "            line = line.strip()\n",
    "            split = line.split(' ')\n",
    "            start_time = parseTime(split[-2])\n",
    "            end_time = parseTime(split[-1])\n",
    "            duration = end_time - start_time\n",
    "            topic_index = int(split[1].replace('.', ''))\n",
    "            topic_label = ' '.join(split[2:-2])\n",
    "            \n",
    "            # Extract frames for this topic/fragment\n",
    "            fragment_frames = erd.extract_fragment(openface_features, start_time, end_time)\n",
    "            \n",
    "            # Aggregate the values\n",
    "            aggregated_row = erd.aggregate_frames(fragment_frames, video_aggregates)\n",
    "            \n",
    "            # Combine results with information for this topic\n",
    "            aggregated_row['start_time'] = start_time\n",
    "            aggregated_row['end_time'] = end_time\n",
    "            aggregated_row['duration'] = duration\n",
    "            aggregated_row['topic_index'] = topic_index\n",
    "            aggregated_row['topic_label'] = topic_label\n",
    "            \n",
    "            aggregated_features = pd.concat([aggregated_features, aggregated_row], ignore_index=True)\n",
    "            \n",
    "    output_file = \"_\".join([participant, session, experiment, memory]) + \"_aggregated.csv\"\n",
    "    output_path = os.path.join(AGG_FEATURES_DIR, output_file)\n",
    "    print(output_path)\n",
    "    aggregated_features.to_csv(output_path, float_format='%g', index=False)\n",
    "    return aggregated_features\n",
    "    \n",
    "\n",
    "# print(os.getcwd())\n",
    "results = process_file('P12_S2_LSB_HM1_topics.txt')\n",
    "#results = process_file('P1_S2_LSB_HM1_topics.txt')\n",
    "#process_file('P2_S2_LSB_HM1_topics.txt')\n",
    "#process_file('P11_S2_LSB_SM1_topics.txt')\n",
    "#print(results[['AU04_int_freq', 'AU04_pres_freq']])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(TOPICS_DIR)\n",
    "files.sort()\n",
    "for file in files:\n",
    "    if file.endswith('.txt'):\n",
    "        print(\"Processing\", file)\n",
    "        aggregated_features = process_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
